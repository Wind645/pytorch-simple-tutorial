{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1\n",
    "## 写在前边：\n",
    "想到当初自己初学pytorch框架的时候，现有的很多教程基本都从很高的高度开始讲解，\n",
    "给我当时带来很大的困扰。\n",
    "写这些tutorial的动机有两个，一个是尽我所能提供一个比较保姆级的教程，帮助大家\n",
    "快速上手pytorch框架，另一个动机是我选修的COE101这门课正好需要做project，很多\n",
    "同学可能想学些代码知识，故在此尽我可能的为大家提供帮助。\n",
    "\n",
    "我菜菜的，tutorial里可能会有很多不准确不恰当的地方，可以加我微信或者email我  \n",
    "12410615@mail.sustech.edu.cn  我会更改，大家有什么更好的建议也可以来找我讨论呀\n",
    "\n",
    "本tutorial希望大家对深度学习、线性代数有一个大致的认识，我会尽我可能将pytorch框架清楚的讲解一下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tutorial 1 content\n",
    "1. 什么是pytorch，如何下载pytorch\n",
    "2. device是什么，我应该选择什么device\n",
    "3. 什么是张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch简介与下载方式\n",
    "### pytorch到底是什么呢？\n",
    "先说一个标准的概念，pytorch是一种深度学习的框架。那什么是框架？这是个什么神奇的东东？\n",
    "我先卖个关子，放到后边解释。\n",
    "\n",
    "首先我们需要知道的是，我们在编程的时候，一般并不是从最基础功能写起，举个例子，每门编程语言\n",
    "里边都会有很多的库，这些库里边把很多功能写完，然后我们要用到这些功能就不用自己手搓那么麻烦，\n",
    "可以直接调用库里的函数（这里的概括可能不太准确，计系的同学补药打我）。打个比方，如果我们要\n",
    "放一场烟花，一场非常盛大的烟花，那么我们需要干什么呢？需要买很多的万花筒，然后把不同的万花筒\n",
    "放在一起点燃，就可以放这么一场盛大的烟花。但是一个很重要的点是，不过烟花多么盛大，它都是很多个小\n",
    "的火箭筒一起组成的，而这些小的火箭筒，被厂商一起放到了一个万花筒的盒子里。这个盒子，就可以类比\n",
    "为我们的pytorch框架，有了它，我们不需要考虑怎么组合每个小火箭筒，只需要考虑怎么组合我们的万花筒。\n",
    "嗯，就酱紫。\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 怎么下载pytorch\n",
    "\n",
    "pytorch是python里的库，也就是说想用pytorch只能用python哦。当然同样的深度学习框架还有很多，\n",
    "比如tensorflow、keras等等，但是笔者只会pytorch，所以只能写pytorch的tutorial（枯）。\n",
    "\n",
    "偏题了，话归正题，使用pip下载是最简单粗暴的方式，不知道pip是什么的同学可以AI问问或者看这里  \n",
    "https://blog.csdn.net/Dome_/article/details/89763579 我们可以使用最简单的pip下载方式。\n",
    "简单来说pip是个可以方便你下载库的东西（应该可以这么概括吧，计系的人还是别杀了我）。（当然conda也可以）\n",
    "\n",
    "有了pip后，我们在终端执行'pip install '命令就可以直接下载对应库了\n",
    "\n",
    "大家可以进入pytorch官网 https://pytorch.org/  进入之后是全英的，但是不用慌，啥也不用点，往下划，\n",
    "会看到一个**INSTALL PYTORCH**然后大家选择自己对应的电脑操作系统，版本，然后把下边的下载命令复制下来，在自己电脑终端上运行就好了。它会提供你一个类似下边这样的指令。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后应该就可以无痛下载了，要是报错了或者有啥问题建议CSDN或者AI问问细节。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## device是什么，我应该选择什么device\n",
    "### device是什么\n",
    "ok，现在进入一个很重要的概念，就是device(设备)。\n",
    "\n",
    "首先我们需要知道的是，深度学习一般要用计算机进行一个非常巨量的计算，这种计算很多时候我们的电脑中央处理器（CPU）可能处理不来，或者说，算的很慢。然后我们会需要用到一个新的设备————GPU，（一般用NVIDIA显卡）这种东西可以帮助我们加速这种深度学习的计算。那问题来了，没有配备GPU可以拿CPU跑项目吗，答案是of course，但是有内存炸掉的风险和算的过慢的风险，所以最好别拿自己的CPU跑太大的项目。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 怎么选择device\n",
    "我们可以通过一个简单的命令看看自己的电脑能不能用GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available(): \n",
    "    #这里torch自动检查可不可以调用GPU，至于这里为什么写的是cuda而不是GPU，大家可以去搜搜cuda是什么，\n",
    "    #就不展开细讲了，可以简单理解为cuda是GPU的女朋友，调用cuda就是调用GPU（暴论）\n",
    "    device = torch.device('cuda')\n",
    "    #如果可以调用GPU，这里就会把device设定为GPU\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    #如果不可以，没关系还有cpu\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好的，问题来了，如果自己的电脑只有CPU，跑不动大的项目怎么办？我们可以去网上租用GPU，比如autodl这样的平台是可以租GPU用的，至于怎么租，那有是比较麻烦的东西，就不细讲啦，大家可以自己去了解了解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 什么是张量\n",
    "这是一个很重要的点，这个张量不是数学上的张量，而是pytorch中的一种特殊的数据结构，\n",
    "它可以是0维（标量），1维（向量），2维（矩阵）或者更高维度。我们使用pytorch做项目的时候，\n",
    "最好把所有的数据都转化为pytorch张量进行处理，这样会带来非常多的好处，大家以后多用用会深有体会。\n",
    "（有的时候numpy也会用到，这个就先不细讲，但是非常建议大家去了解一下）创建张量也很简单，看下边！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([6])#创建一个标量！\n",
    "b = torch.tensor([[1, 2],\n",
    "                  [3, 4]])#创建一个矩阵！\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上边是一个创建张量很简单的示例。下边讲一个稍微有点烧脑的事情，如果看不懂也没事，可以后边再理解。\n",
    "\n",
    "这个事情是，你的张量创建在哪里？\n",
    "我先前讲到了device 可以选择cpu或gpu，那么你的张量是创建在gpu上还是cpu上呢？\n",
    "需要注意到的一个地方是，如果我们有gpu，而我们的张量创建在cpu上，是很有可能让我们后期的训练变得很慢的，\n",
    "我们可以这么理解，如果张量创建在cpu上，但我们用的device是gpu，那么我们每次计算，都要先把我们的cpu上的数据给拽到gpu上再算，这个步骤太麻烦了，可能让我们的计算变得很慢，所以如果有gpu，就把张量放在gpu上，如果只有cpu，那就放在cpu上好啦。\n",
    "\n",
    "诶，怎么放到gpu上呢？见下，可以创建完再放到gpu上，也可以直接在gpu上创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "a1 = torch.tensor([1, 2],device=device) #直接在gpu上创建张量\n",
    "a2 = torch.tensor([3, 4])\n",
    "a2.to(device) #创建完了再挪到gpu上，两种方式都可以。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "嗯，tutorial1就到这里叭。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
